// server.js â€” NovaLink Hybrid AI Proxy
// ÙŠØ¹Ù…Ù„ Ù…Ø¹ Gemini Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø«Ù… OpenAI Ø§Ø­ØªÙŠØ§Ø·ÙŠØ§Ù‹ØŒ Ù…Ø¹ Ø¯Ø¹Ù… Dotenv ØªÙ„Ù‚Ø§Ø¦ÙŠ.

import express from "express";
import fetch from "node-fetch";
import cors from "cors";
import dotenv from "dotenv";

dotenv.config();

const app = express();
app.use(express.json());

// Ø§Ù„Ø³Ù…Ø§Ø­ ÙÙ‚Ø· Ù„Ø¯ÙˆÙ…ÙŠÙ† Ù†ÙˆÙØ§ Ù„ÙŠÙ†Ùƒ
const allowedOrigins = [
  "https://novalink-ai.com",
  "https://www.novalink-ai.com"
];

app.use(
  cors({
    origin: function (origin, callback) {
      if (!origin) return callback(null, true);
      if (allowedOrigins.includes(origin)) {
        return callback(null, true);
      }
      return callback(new Error("Not allowed by CORS"), false);
    }
  })
);

// Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø¨ÙŠØ¦Ø©
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// ØµÙŠØ§ØºØ© Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¨Ù†ØºÙ…Ø© Ù†ÙˆÙØ§ Ù„ÙŠÙ†Ùƒ
function buildPrompt(question, context) {
  let base =
    "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ø±Ø¨ÙŠ Ù…Ø­ØªØ±Ù ÙŠÙ…Ø«Ù„ Ù…Ù†ØµØ© Ù†ÙˆÙØ§ Ù„ÙŠÙ†Ùƒ Ø§Ù„Ù…Ù‡ØªÙ…Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„Ø£Ø¹Ù…Ø§Ù„.\n" +
    "Ø£Ø¬Ø¨ Ø¨Ø¬Ù…Ù„ Ù‚ØµÙŠØ±Ø© ÙˆÙˆØ§Ø¶Ø­Ø© ÙˆØ¨Ø£Ø³Ù„ÙˆØ¨ Ø¨Ø´Ø±ÙŠ Ø¹Ù…Ù„ÙŠ.\n" +
    "Ù„Ø§ ØªØ°ÙƒØ± ØªÙØ§ØµÙŠÙ„ ØªÙ‚Ù†ÙŠØ© Ù…Ø¹Ù‚Ø¯Ø© Ø¥Ù„Ø§ Ø¹Ù†Ø¯ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….\n" +
    "ØªØ­Ø¯Ø« ÙƒÙ†ØµÙŠØ­Ø© Ù…Ù† ØµØ¯ÙŠÙ‚ Ø®Ø¨ÙŠØ± ÙˆÙ„ÙŠØ³ ÙƒØ¢Ù„Ø©.\n\n";

  if (context && context.title) {
    base += `ðŸ§  Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ù†ÙˆÙØ§ Ù„ÙŠÙ†Ùƒ:\n` +
            `Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: ${context.title}\n` +
            `Ø§Ù„ÙˆØµÙ: ${context.description || ""}\n` +
            `Ù…Ù‚ØªØ·Ù: ${context.excerpt || ""}\n\n`;
  }

  base += `Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:\n${question}\n\n`;
  base += "Ø§Ù„Ø¢Ù† Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙˆØ§Ø¶Ø­Ø© Ø¯ÙˆÙ† Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„ÙƒÙˆÙ†Ùƒ Ù†Ù…ÙˆØ°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.";
  return base;
}

// Gemini
async function callGemini(question, context) {
  if (!GEMINI_API_KEY) return null;
  const prompt = buildPrompt(question, context);

  const res = await fetch(
    "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent",
    {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "x-goog-api-key": GEMINI_API_KEY
      },
      body: JSON.stringify({
        contents: [{ role: "user", parts: [{ text: prompt }] }]
      })
    }
  );

  if (!res.ok) throw new Error("Gemini HTTP " + res.status);
  const data = await res.json();
  return data?.candidates?.[0]?.content?.parts?.[0]?.text?.trim() || null;
}

// OpenAI
async function callOpenAI(question, context) {
  if (!OPENAI_API_KEY) return null;
  const prompt = buildPrompt(question, context);

  const res = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: "Bearer " + OPENAI_API_KEY
    },
    body: JSON.stringify({
      model: "gpt-4.1-mini",
      messages: [
        { role: "system", content: "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ø±Ø¨ÙŠ ÙŠÙ…Ø«Ù„ Ù†ÙˆÙØ§ Ù„ÙŠÙ†Ùƒ." },
        { role: "user", content: prompt }
      ],
      temperature: 0.6,
      max_tokens: 500
    })
  });

  if (!res.ok) throw new Error("OpenAI HTTP " + res.status);
  const data = await res.json();
  return data?.choices?.[0]?.message?.content?.trim() || null;
}

// Ù†Ù‚Ø·Ø© Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
app.post("/api/nova-ai", async (req, res) => {
  try {
    const { question, context, prefer } = req.body || {};
    if (!question) {
      return res.status(400).json({ ok: false, error: "no_question" });
    }

    let answer = null;
    const useGeminiFirst = prefer !== "openai-first";

    if (useGeminiFirst) {
      answer = await callGemini(question, context).catch(() => null);
      if (!answer) answer = await callOpenAI(question, context).catch(() => null);
    } else {
      answer = await callOpenAI(question, context).catch(() => null);
      if (!answer) answer = await callGemini(question, context).catch(() => null);
    }

    if (!answer) {
      return res.json({
        ok: false,
        error: "ai_failed",
        message: "ØªØ¹Ø°Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø­Ø§Ù„ÙŠØ§Ù‹."
      });
    }

    res.json({ ok: true, answer });
  } catch (err) {
    console.error("Proxy error:", err);
    res.status(500).json({ ok: false, error: "server_error" });
  }
});

// Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø³ÙŠØ±ÙØ±
app.get("/", (req, res) => {
  res.send("âœ… NovaLink Hybrid AI Proxy is running.");
});

// ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ±
const PORT = process.env.PORT || 3000;
app.listen(PORT, () =>
  console.log("ðŸš€ NovaLink Hybrid Proxy listening on port", PORT)
);
